{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-Layer Perceptrons (MLPs)\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter Settings\n",
    "-------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "use_gpu = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST Data Loading\n",
    "-------------------\n",
    "\n",
    "MNIST images show digits from 0-9 in 28x28 grayscale images. We normalize and center them around 0, which gives a slight performance boost during training.\n",
    "We create both a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = MNIST(root='./data/MNIST', download=True, train=True, transform=img_transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = MNIST(root='./data/MNIST', download=True, train=False, transform=img_transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP Definition\n",
    "-----------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 669706\n"
     ]
    }
   ],
   "source": [
    "class MultilayerPerceptron(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultilayerPerceptron, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=28*28, out_features=512) # MNIST resolution is 28 x 28\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=512)\n",
    "        self.fc3 = nn.Linear(in_features=512, out_features=10) # 10 outputs: probability for each digit class\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # flatten MNIST image to a vector\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        # Softmax transforms the 10 scores for each class to probabilities that sum up to 1.\n",
    "        # The cross-entropy between these class probabilities and the ground truth class probabilities\n",
    "        # will be used as a loss when comparing to the ground truth.\n",
    "        # Cross-entropy computes a logarithm over the class probabilities, and it is numerically more stable\n",
    "        # to combine the softmax computation with the logarithm, which is done below:\n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "mlp = MultilayerPerceptron()\n",
    "if use_gpu:\n",
    "    mlp = mlp.cuda()\n",
    "\n",
    "num_params = sum(p.numel() for p in mlp.parameters() if p.requires_grad)\n",
    "print('Number of parameters: %d' % num_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train MLP\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Epoch [1 / 20] average reconstruction error: 0.319186\n",
      "Epoch [2 / 20] average reconstruction error: 0.135708\n",
      "Epoch [3 / 20] average reconstruction error: 0.100948\n",
      "Epoch [4 / 20] average reconstruction error: 0.079256\n",
      "Epoch [5 / 20] average reconstruction error: 0.069259\n",
      "Epoch [6 / 20] average reconstruction error: 0.054934\n",
      "Epoch [7 / 20] average reconstruction error: 0.052416\n",
      "Epoch [8 / 20] average reconstruction error: 0.045728\n",
      "Epoch [9 / 20] average reconstruction error: 0.039146\n",
      "Epoch [10 / 20] average reconstruction error: 0.034199\n",
      "Epoch [11 / 20] average reconstruction error: 0.032968\n",
      "Epoch [12 / 20] average reconstruction error: 0.026997\n",
      "Epoch [13 / 20] average reconstruction error: 0.029103\n",
      "Epoch [14 / 20] average reconstruction error: 0.022064\n",
      "Epoch [15 / 20] average reconstruction error: 0.025578\n",
      "Epoch [16 / 20] average reconstruction error: 0.024577\n",
      "Epoch [17 / 20] average reconstruction error: 0.026174\n",
      "Epoch [18 / 20] average reconstruction error: 0.017527\n",
      "Epoch [19 / 20] average reconstruction error: 0.023077\n",
      "Epoch [20 / 20] average reconstruction error: 0.017892\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(params=mlp.parameters(), lr=learning_rate)\n",
    "\n",
    "# set to training mode\n",
    "mlp.train()\n",
    "\n",
    "train_loss_avg = []\n",
    "\n",
    "print('Training ...')\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss_avg.append(0)\n",
    "    num_batches = 0\n",
    "    \n",
    "    for image_batch, label_batch in train_dataloader:\n",
    "        \n",
    "        image_batch = Variable(image_batch)\n",
    "        label_batch = Variable(label_batch)\n",
    "        if use_gpu:\n",
    "            image_batch = image_batch.cuda()\n",
    "            label_batch = label_batch.cuda()\n",
    "        \n",
    "        # class predictions\n",
    "        prediction_batch = mlp(image_batch)\n",
    "        \n",
    "        # The cross-entropy loss.\n",
    "        # The first input are the predicted log class probabilities.\n",
    "        # The ground truth probabilites for each image are expected to be\n",
    "        # 1 for a single class and 0 for all other classes.\n",
    "        # This function expects as second input the index of the class with probability 1.\n",
    "        # (this function is not called cross-entropy, since this function assumes\n",
    "        # that the inputs are log probabilities, not probabilities).\n",
    "        loss = F.nll_loss(prediction_batch, label_batch)\n",
    "        \n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # one step of the optmizer (using the gradients from backpropagation)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss_avg[-1] += loss.data[0]\n",
    "        num_batches += 1\n",
    "        \n",
    "    train_loss_avg[-1] /= num_batches\n",
    "    print('Epoch [%d / %d] average reconstruction error: %f' % (epoch+1, num_epochs, train_loss_avg[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Training Curve\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3XmcHHWd//HXZ+4jx2SOQI6Z3EQC\ngQBjwn0oQjwgoigg/GSRXX6orLisB64XsutvkV0ED2QFYdcDjYCIWY1C5BLEQCbkIoGQIefknCPJ\nZHLM+fn90TVJZ9IzXZNMT/dMv5+PRz+6uupb1Z9UevrTVfX9fsrcHRERkZ5kJDsAERFJfUoWIiIS\nl5KFiIjEpWQhIiJxKVmIiEhcShYiIhKXkoWIiMSlZCEiInEpWYiISFxZyQ6gr5SWlvr48eOTHYaI\nyICyePHiOncvi9du0CSL8ePHU1VVlewwREQGFDPbEKadTkOJiEhcShYiIhKXkoWIiMSlZCEiInEp\nWYiISFxKFiIiEpeShYiIxJX2yWL3vla+9+c1LNu0K9mhiIikrEEzKO9oWQbc++e3ycvO4NTyomSH\nIyKSktL+yGJYXjZFBdlsbNiX7FBERFJW2icLgIriAiULEZEeKFkQSRablCxERLqlZEEkWdTs3E97\nhyc7FBGRlKRkQSRZtHU4W3btT3YoIiIpScmCSLIAdCpKRKQbShZAeZAsdJFbRCQ2JQtg1PA8sjJM\nyUJEpBsJTRZmNtvMVptZtZndHmP5zWa2wsyWmtnLZjYtatlXgvVWm9mliYwzKzODMSPylSxERLqR\nsGRhZpnA/cD7gWnANdHJIPBLd5/u7jOAu4HvButOA64GTgJmAz8Ktpcw6j4rItK9RB5ZzASq3X2t\nu7cAc4E50Q3cvTHqZSHQ2Xd1DjDX3ZvdfR1QHWwvYco1ME9EpFuJTBZjgE1Rr2uCeYcxs8+a2TtE\njiw+15t1+9K44gJ27mul8UBrIt9GRGRASmSysBjzjhj15u73u/sk4MvA13qzrpndZGZVZlZVW1t7\nTMGq+6yISPcSmSxqgPKo12OBLT20nwt8uDfruvuD7l7p7pVlZWXHFOzB7rP1ShYiIl0lMlksAqaY\n2QQzyyFywXpedAMzmxL18oPAmmB6HnC1meWa2QRgCvBaAmOlokRjLUREupOw+1m4e5uZ3QI8DWQC\nj7j7SjO7E6hy93nALWZ2MdAK7ASuD9ZdaWaPAauANuCz7t6eqFhBpcpFRHqS0Jsfuft8YH6Xed+I\nmr61h3W/DXw7cdEdSaXKRURi0wjuKOUaayEiEpOSRRSVKhcRiU3JIsq4oFT51t0qVS4iEk3JIkqF\nqs+KiMSkZBGlXAPzRERiUrKI0lmqfIMG5omIHEbJIopKlYuIxKZk0YVKlYuIHEnJoguVKhcROZKS\nRRcVKlUuInIEJYsuVKpcRORIShZdKFmIiBxJyaILlSoXETmSkkUXKlUuInIkJYsYIqXKVR9KRKST\nkkUM5cUFbKzfm+wwRERShpJFDCpVLiJyOCWLGCpUqlxE5DBKFjGoVLmIyOGULGLQWAsRkcMpWcTQ\nWapcRxYiIhFKFjEcKlWuaxYiIqBk0a0KVZ8VETlIyaIb5bqvhYjIQQlNFmY228xWm1m1md0eY/lt\nZrbKzJab2bNmNi5qWbuZLQ0e8xIZZywVxQU07G1hj0qVi4gkLlmYWSZwP/B+YBpwjZlN69JsCVDp\n7qcATwB3Ry3b7+4zgsfliYqzO+o+KyJySCKPLGYC1e6+1t1bgLnAnOgG7v68u3d+Gy8ExiYwnl5R\n91kRkUMSmSzGAJuiXtcE87pzI/DHqNd5ZlZlZgvN7MOJCLAn5TqyEBE5KCuB27YY82IWWzKz64BK\n4IKo2RXuvsXMJgLPmdkKd3+ny3o3ATcBVFRU9E3UgeH52QzPV6lyERFI7JFFDVAe9XossKVrIzO7\nGPgqcLm7N3fOd/ctwfNa4AXgtK7ruvuD7l7p7pVlZWV9Gz0wrkSlykVEILHJYhEwxcwmmFkOcDVw\nWK8mMzsN+DGRRLEjav4IM8sNpkuBc4BVCYw1JnWfFRGJSFiycPc24BbgaeBN4DF3X2lmd5pZZ++m\n/wCGAI936SJ7IlBlZsuA54G73L3fk0WkVPk+lSoXkbSXyGsWuPt8YH6Xed+Imr64m/VeAaYnMrYw\nKooLaG13tjUeYExRfrLDERFJGo3g7kFn99kNumueiKQ5JYseaKyFiEiEkkUPRg3PI1OlykVElCx6\nkpWZwZgilSoXEYmbLMzsY2Y2NJj+mpk9aWanJz601KBS5SIi4Y4svu7ue8zsXOBS4KfAA4kNK3VU\nlGishYhImGTRHjx/EHjA3X8H5CQupNSiUuUiIuGSxWYz+zHwcWB+MLI6ba51HOoRpesWIpK+wnzp\nf5zIKOzZ7r4LKAa+mNCoUojuayEiEm4E9yjgD+7ebGYXAqcAP0toVCnkUKlyDcwTkfQV5sjiN0C7\nmU0GHgYmAL9MaFQpRKXKRUTCJYuOoCjgR4D73P2fiBxtpI1I91ldsxCR9BUmWbSa2TXAJ4HfB/Oy\nExdS6qlQqXIRSXNhksUNwFnAt919nZlNAH6R2LBSS0WJSpWLSHqLmyyC+0h8AVhhZicDNe5+V8Ij\nSyHRpcpFRNJRmHIfFwJrgPuBHwFvm9n5CY4rpRzsPluvU1Eikp7CnIa6B7jE3S9w9/OJlPy4N7Fh\npRaVKheRdBcmWWS7++rOF+7+Nml2gVulykUk3YUZlFdlZg8DPw9eXwssTlxIqaezVPkGJQsRSVNh\nksWngc8CnwMM+AuRaxdpRaXKRSSdxU0W7t4MfDd4pK3y4gKeXrkt2WGIiCRFt8nCzFYA3Q4scPdT\nEhJRioouVT40L60u2YiI9Hhk8aF+i2IAGFdyqFT5tNFKFiKSXrpNFu6+oT8DSXXRpcqnjR6W5GhE\nRPpXQm9iZGazzWy1mVWb2e0xlt9mZqvMbLmZPWtm46KWXW9ma4LH9YmMM4xyjbUQkTSWsGRhZplE\nRn2/H5gGXGNm07o0WwJUBtc/ngDuDtYtBr4JzAJmAt80sxGJijUMlSoXkXQWptzHh8zsaJLKTKDa\n3de6ewswF5gT3cDdn3f3zm/fhcDYYPpSYIG7N7j7TmABMPsoYuhT6j4rIukqTBK4GlhjZneb2Ym9\n2PYYYFPU65pgXnduBP7Ym3XN7CYzqzKzqtra2l6EdnSULEQkXYWpOnsdcBrwDvDfZva34Et6aJxV\nLdbmYjY0uw6oBP6jN+u6+4PuXunulWVlZXHCOXblxSpVLiLpKdTpJXdvJHJ71blE7pJ3BfC6mf1j\nD6vVAOVRr8cCW7o2MrOLga8ClwcDAEOv299UqlxE0lWYaxaXmdlvgeeIFBCc6e7vB04lcp+L7iwC\nppjZBDPLIXI6a16XbZ8G/JhIotgRtehp4BIzGxFc2L4kmJdUKlUuIukqTG2ojwH3uvtfome6+z4z\n+1R3K7l7m5ndQuRLPhN4xN1XmtmdQJW7zyNy2mkI8LiZAWx098vdvcHM/pVIwgG4090bev2v62OH\nBubt46xJJUmORkSk/4SpDfVJMzvezC4nct1gkbtvC5Y9G2fd+cD8LvO+ETV9cQ/rPgI8Ei++/qRS\n5SKSrsKchroReA34CHAlsLCnI4rBrLNUuZKFiKSbMKehvgSc5u71AGZWArxCiv3q7y/qPisi6ShM\nb6gaYE/U6z0cPgYirZQXF6jkh4iknTBHFpuBV83sd0SuWcwBXjOz2wDcPa3uc1FRXED93haamtsY\nkhtm94mIDHxhvu3eCR6dfhc8xxuUNyhFd59V9VkRSRdhekN9CyAYse3u3pTwqFKYSpWLSDoK0xvq\nZDNbArwBrDSzxWZ2UuJDS00VKlUuImkozAXuB4Hb3H2cu48D/hl4KLFhpa7hBSpVLiLpJ0yyKHT3\n5ztfuPsLQGHCIhoA1H1WRNJNmGSx1sy+bmbjg8fXgHWJDiyVVaj7rIikmTDJ4lNAGfBk8CgFbkhk\nUKkuUqp8v0qVi0ja6LE3VHBr1H9x98/1UzwDQkVxAS3tHWxvPMDoovxkhyMiknA9Hlm4eztwRj/F\nMmBEd58VEUkHYQblLTGzecDjwN7Ome7+ZMKiSnHRA/POnKhS5SIy+IVJFsVAPfCeqHlO5PpFWhpV\npFLlIpJewiSLn7j7X6NnmNk5CYpnQMhWqXIRSTNhekP9IOS8tKKxFiKSTro9sjCzs4CzgbLOCrOB\nYURuk5rWyosLeGbltmSHISLSL3o6DZVD5P7YWRxeYbaRyB3z0ppKlYtIOun2W87dXwReNLP/cfcN\n/RjTgBBdUPDEUao+KyKDW5ifxLlm9iAwPrq9u7+n2zXSQPRYCyULERnswiSLx4H/An4CtCc2nIFD\npcpFJJ2ESRZt7v5AwiMZYIYXZDMsL4sN9UoWIjL4hek6+79m9hkzG2VmxZ2PMBs3s9lmttrMqs3s\n9hjLzzez182szcyu7LKs3cyWBo95If89/aqiRN1nRSQ9hDmyuD54/mLUPAcm9rRSUITwfuB9QA2w\nyMzmufuqqGYbgb8DvhBjE/vdfUaI+JJmXHEhb25tTHYYIiIJF+Ye3BOOctszgWp3XwtgZnOBOcDB\nZOHu64NlHUf5HklVXlzAglXbae9wMjMs2eGIiCRMmHtwF5jZ14IeUZjZFDP7UIhtjwE2Rb2uCeaF\nlWdmVWa20Mw+3Iv1+k10qXIRkcEszDWL/wZaiIzmhsiX/r+FWC/WT+3e3C2owt0rgU8A95nZpCPe\nwOymIKFU1dbW9mLTfUOlykUkXYRJFpPc/W6gFcDd9xM7EXRVA5RHvR4LbAkbmLtvCZ7XAi8Ap8Vo\n86C7V7p7ZVlZWdhN9xklCxFJF2GSRYuZ5RMcFQS/8JtDrLcImGJmE8wsB7gaCNWrycxGmFluMF0K\nnEPUtY5U0VmqXGMtRGSwC5Msvgn8CSg3s0eBZ4EvxVvJ3duAW4CngTeBx9x9pZndaWaXA5jZu82s\nBvgY8GMzWxmsfiJQZWbLgOeBu7r0okoJ2ZkZjC7K05GFiAx6YXpDLTCz14EziZx+utXd68Js3N3n\nA/O7zPtG1PQiIqenuq73CjA9zHskW0VxgQbmicigF+bIAnevd/c/AJVhE0W6qCgu0GkoERn0QiWL\nKJcnJIoBrKK48GCpchGRwaq3yUIjz7pQQUERSQe9TRZnJCSKAUzdZ0UkHYQZwX23mQ0zs2xggZnV\nmdl1/RDbgDCutIDMDOPpN3SLVREZvMIcWVzi7o3Ah4gMtDuBw4sKprVhedl85sJJPLlkM/NXbE12\nOCIiCREmWWQHzx8AfuXuDQmMZ0D63HuncMrY4fzLb1ewbbfqRInI4BP2fhZvAZXAs2ZWBugbMUp2\nZgb3XTWD5tYOvvjEMjo6elMCS0Qk9cVNFu5+O3AWkTEWrcBeIqXGJcrEsiF8/UPTeGlNHf/zyvpk\nhyMi0qfCXOD+GJFbq7ab2deAXwCjEx7ZAHTNzHIuPnEkd/3pLVZv25PscERE+kyY01Bfd/c9ZnYu\ncCnwU0D35I7BzLjro6cwLC+LW+cuobmtPdkhiYj0iTDJovMb74PAA+7+OyAncSENbKVDcrn7ylN4\na9se7nnm7WSHIyLSJ8Iki81m9mPg48D8oHR4bwfzpZX3vOs4rjuzgodeWssr1SqlJSIDX5gv/Y8T\nKTM+2913AcVonEVcX/3ANCaUFvLPjy9j977WZIcjInJMwvSG2ge8A1xqZrcAI939mYRHNsDl52Ry\n31UzqN3TzFefWoG7utOKyMAVpjfUrcCjwMjg8Qsz+8dEBzYYnDK2iH963wn8fvlWfrc09B1lRURS\nTpjTUDcCs9z9G8GNi84E/iGxYQ0eN18wicpxI/j6U29Qs1PFBkVkYAqTLIxDPaIIplWqPKTMDOPe\nq2bgwG2PLaNdo7tFZAAKkyz+G3jVzO4wszuAhcDDCY1qkCkvLuBbl5/Ea+saePAva5MdjohIr4W5\nwP1d4AagAdgJ3ODu9yU6sMHmI6eP4YPTR/HdBat5Y/PuZIcjItIrPSYLM8swszfc/XV3/767f8/d\nl/RXcIOJmfHtK06muDCHW+cuYX+LRneLyMDRY7Jw9w5gmZlV9FM8g1pRQQ73fGwG79Tu5a4/vpns\ncEREQssK0WYUsNLMXiNScRYAd788YVENYudOKeXGcyfw8MvruPBdI7lo6shkhyQiEleYZPGthEeR\nZr546VReXlPHl55Yzp9uPY+SIbnJDklEpEfdnoYys8lmdo67vxj9AJzI7VXjMrPZZrbazKrN7PYY\ny883s9fNrM3Mruyy7HozWxM8ru/tPyyV5WVnct/VM9i9r5WvPKnR3SKS+nq6ZnEfEOumDPuCZT0y\ns0zgfuD9wDTgGjOb1qXZRuDvgF92WbcY+CYwC5gJfNPMRsR7z4HkxFHD+NLsqTyzajuPVW1Kdjgi\nIj3qKVmMd/flXWe6exUwPsS2ZwLV7r7W3VuAuXS5w567rw/eo6PLupcCC9y9wd13AguA2SHec0D5\n1DkTOHtSCd/631VU72hKdjgiIt3qKVnk9bAsP8S2xwDRP5lrgnlhHMu6A0ZGhnHPx08lLzuTq378\nN5Zt2pXskEREYuopWSwysyNqQJnZjcDiENuOVRIk7Mn5UOua2U1mVmVmVbW1tSE3nVpGDc/n8ZvP\nIj8nk6sfXMjzb+1IdkgiIkfoKVl8HrjBzF4ws3uCx4vA3wO3hth2DVAe9XosELb0aqh13f1Bd690\n98qysrKQm049k8qG8ORnzmbSyEL+/mdV/HrRxmSHJCJymG6Thbtvd/eziXSdXR88vuXuZ7n7thDb\nXgRMMbMJZpYDXA3MCxnX08AlZjYiuLB9STBv0Bo5NI+5N53FOZNL+fJvVnDvgrfVS0pEUkbccRbu\n/jzwfG837O5twc2SngYygUfcfaWZ3QlUufs8M3s38FtgBHCZmX3L3U9y9wYz+1ciCQfgTndv6G0M\nA82Q3Cwevr6Srzy5gu89u4Ztuw/w7StOJitTd7EVkeSywfLrtbKy0quqqpIdRp9wd+5d8Dbff66a\ni6aW8cNPnE5hbpjxkyIivWNmi929Ml47/WRNQWbGbZdM5dtXnMyLb9dyzUMLqWtqTnZYIpLGlCxS\n2LWzxvHg/6nk7e17+MiPXmFd3d74K4mIJICSRYq7eNpx/OofzqSpuY2PPvAKSzbuTHZIIpKGlCwG\ngNMqRvCbT5/NkNwsrnloIX9etT3ZIYlImlGyGCAmlBbym0+fzQnHDeWmn1fx6Ksbkh2SiKQRJYsB\npGxoLr/6hzO54IQyvvrbN7jnmdUaiyEi/ULJYoApzM3ioU9WclVlOT94rpovPL6c1vaudRhFRPqW\nOu8PQFmZGdz10emMKsrjvj+vYceeA/zgmtMoKshJdmgiMkjpyGKAMjM+f/EJfOej03nlnXpm/b9n\n+cLjy1i6aZdOTYlIn9ORxQB31bsrOLW8iJ/9bQNPLdnME4trOGn0MK47cxxzZoymIEf/xSJy7FTu\nYxDZc6CVp5Zu4dGFG3hr2x6G5mZxxeljuO7McZxw3NBkhyciKShsuQ8li0HI3Vm8YSePvrqRPyzf\nSkt7BzPHF3PtmRXMPvl4crMykx2iiKQIJQsBoGFvC49XbeKXr21kQ/0+Sgpz+FhlOdfOqqC8uCDZ\n4YlIkilZyGE6OpyXq+v4xcIN/PnN7ThwwQllXDtrHO9510gyM2LdnFBEBjslC+nW1t37mfvaJuYu\n2sj2xmZGD8/j0xdN5hMzK5Q0RNKMkoXE1drewbNvbufhl9exaP1OThw1jDsum8asiSXJDk1E+onu\nZyFxZWdmMPvkUTz2f8/iR9eeTuP+Vq56cCH/+KslbNm1P9nhiUgKUbIQzIwPTB/Fn2+7gFvfO4Vn\nVm7jvfe8yA+fW8OB1vZkhyciKUDJQg7Kz8nkn953An++7QIunFrGfz7zNu+790WeWblNo8JF0pyS\nhRyhvLiAB647g0f/fhZ5WZnc9PPFfPKR16jesSfZoYlIkihZSLfOmVzK/FvP45uXTWPppl3Mvu8l\n/u33q2g80Jrs0ESknylZSI+yMzO44ZwJvPCFC/lY5Vge/us63vOfL/BY1SY6OnRqSiRdKFlIKCVD\ncvn3j5zCvM+eS0VxAV96YjlX6J7gImlD4yyk19ydp5Zu5t/nv8WOPc1cecZYLjt1NMcPy+O4YbkM\nz8/GTIP7RAaClBiUZ2azge8BmcBP3P2uLstzgZ8BZwD1wFXuvt7MxgNvAquDpgvd/eae3kvJov81\nNbfxg+fW8MjL62htP/Q5ys3K4LggcUSeu07ncfywPPJzVNBQJNmSnizMLBN4G3gfUAMsAq5x91VR\nbT4DnOLuN5vZ1cAV7n5VkCx+7+4nh30/JYvkqWtqZn3dXrY1HmB7YzM7Gg8E0wfY0djMtsYD7Gs5\ncrzG0Lys4Ggkj+ljh3PelFLOGDdCVXFF+lHYZJHIO+PMBKrdfW0Q0FxgDrAqqs0c4I5g+gngh6bz\nFwNO6ZBcSofkdrvc3WlqbmN7kEy2B8lkRzC9Zdd+HvrLWh544R3yszM5c2Ix500p4/wTSplUNkSn\ntERSQCKTxRhgU9TrGmBWd23cvc3MdgOdhYkmmNkSoBH4mru/lMBYJYHMjKF52QzNy2byyNg3YWpq\nbmPhO/W8tKaWl9bU8fzqyG+KUcPzOG9KKedNKeOcyaUUF+o+4yLJkMhkEevnYNdzXt212QpUuHu9\nmZ0BPGVmJ7l742Erm90E3ARQUVHRByFLsgzJzeLiacdx8bTjANjUsI+Xq+t4aU0tf3pjG49V1WAG\n08cMP5g8Tq8YQU6WOvSJ9IdEXrM4C7jD3S8NXn8FwN3/ParN00Gbv5lZFrANKPMuQZnZC8AX3L3b\nixK6ZjF4tXc4y2t28dKaSPJ4feMu2jucgpxMzppYwnlTSjl3ShmTygp1ykqkl1LhmsUiYIqZTQA2\nA1cDn+jSZh5wPfA34ErgOXd3MysDGty93cwmAlOAtQmMVVJYZoZxWsUITqsYwefeO4XGA63BKatI\n8nj2rR1A5JTVuZNLOXdKKedMLu3xOoqI9E7CkkVwDeIW4GkiXWcfcfeVZnYnUOXu84CHgZ+bWTXQ\nQCShAJwP3GlmbUA7cLO7NyQqVhlYhuVlc8lJx3PJSccDsLF+Hy9V1/LymjqeWbWdxxfXADBt1DDO\nnVLKuZNLmTmhmLxs9bISOVoalCeDSnuHs2Lzbv4aXO9YvGEnre1OTlYG7x4/gnMnl3HelFKmjRpG\nhu4KKJL8cRb9TclCYtnX0sar6xp4eU0dL6+pY/X2SOXc4sIczp506HrHmKL8JEcqkhypcM1CJOkK\ncrK4aOpILpo6EoAdjQd4uTqSOF6qruP3y7cCMKYon+ljhjN97PDI85jhjFA3XZGDdGQhacvdeXt7\nEy9X17F00y5W1Oxiff2+g8vLi/M5ZUzRwQRy8pjhDM/PTmLEIn1PRxYicZgZU48fytTjDw0U3L2/\nlZWbd7N8825W1Oxm+eZd/GHF1oPLx5cUMH1sEacEyePkMcMYmqcEIoOfkoVIlOH52Zw9uZSzJ5ce\nnLdzbwtvbNnN8ppIAnl9w07+d9mWg8snlhUyeng+hbmZFOZmMSQ369BzzqF5BblZDAnaFOYcaqeB\nhTIQKFmIxDGiMIfzppRx3pSyg/Pqm5pZERx9rNi8m9qmZnbsOcDe5nb2trSxt7ntsEq8PcnJzGBi\nWSGzJhQzc0IJMycUUzZUY0QkteiahUiCNLe1R5JHcxtNzZEEsrely+vmNvYcaGPV1kYWb9h5sDpv\nJHmUMGtCMbMmFjNquHprSWLomoVIkuVmZZKblRm6+GFrewdvbN7Nq+saeG1dA79ftoVfvbYRiFxs\nnxUcdZw5oYTy4vyjKm3i7uxraae+qYW6vc3UN7VQ39TM8cPzOHNiiQYuSrd0ZCGSoto7nDe3NgbJ\no57X1jWwc18rECltMnNCMTMnFDNrQgnD8rKoa2qhPkgAdU3N1O+NJIK6pqjnvc0caO2I+X552Rmc\nPamUi6aWceHUkZQXF/TnP1eSRIPyRAaZjg5nzY4mXltXz8J1Dby6toG6puZu22dnGiWFuZQMyaFk\nSC6lhTkHp0sKcygdElk2oiCHd2qbeGF1Lc+9tYONDZHuw5PKCiNjVN41ksrxibsp1Z4DrRxo7SA/\nJ5P87EwyEzCyvrW9g8b9rewOHo0H2g5N729lTFE+F087jiG56XeyRclCZJBzd9bV7WXR+gZa253S\nqERQMiSXYXlZvT5V1bnNF1bX8vzqHby6toGW9g4KczI5e3IpF00dyYVTyxjdyxHvTc1trK/by7q6\nvayv28v6+n2sr49M1+9tOaxtTlYGBUHi6EwgBTmZ5OdkkZ+dQUFOFnmd84I2be1+8Ms/kgxaD0sO\nse7U2FVedgbvm3Y8c04dzfknlKVNLzUlCxE5Zvta2nilup4X3t7B82/VsnnXfgDedfxQLphaxkVT\nR3LGuBFkZ2awt7ktSACRRLCubi8b6veyrm7fEUdAxw3LZXxJIRNKCxlXUsiQ3Ez2tbSzv7Wd/cHz\nYa9jLDvQ2s6+ljY6gq+wwpxMhudnMyw/+7DnzsewvCyGF0S/PtTujc27eWrpZv6wfCs797VSVJDN\nB6aP4sMzxlA5bkRC6oh1JubFG3biDqeWFzF55JCEHFn1RMlCRPqUu1O9o+ngUUfnEc3Q3CzycjKp\n3XN4Qhg5NJfxpYWMLylgfGkhE0oKGV9ayLiSAgpy+uZ0j7vT3NZBZoaRnXnsRwKt7R28tKaWp5Zs\nYcGq7exvbWdMUT6XnTqaOTNGc+KoYUe97f0t7Syv2cXijTt5fcNOFm/YefAaVKeCnEymjxnOjPIi\nZpQXcWp5EaOG5yX0Pi1KFiKSUHsOtPLX6nr+sqaWlrYOJpQWMr6kkPGlBYwvKaRwgJ//39vcxoJV\n2/nd0s38ZU0d7R3O1OOGcvmMSOIYO6LnDgDbdh9gcZAUFm9oYOWWRtqCw6CJZYWcUTGCM8ZFHpkZ\nxrKaXSzbtJslm3bx5pZGWtojHRHKhuZy6tgiTqso4tSxkfIzfVl2RslCRKSP1Dc1M3/FVp5auoXF\nG3YCUDluBHNOG8MHp49iWF7+iaeOAAAH70lEQVQWb27dw+INDSzeuIvXN+w8eMouNyuDU8uLOGPc\nCCrHRW7iFa87dXNbO29t3cPSTbtYtmkXS2t2sbZ278HlE8sKDx19jC3ixFHDjvoai5KFiEgCbGrY\nx7xlW3hqyWbW7GgiKzgFtr81chH9+GF5nDF+xMEjh2P5Io+2e18ryzcHySN41DVFOgecOGoYf7z1\nvKParpKFiEgCuTtvbt3DvGVbONDazunBkUNve4ody/tv2X2AZZsi96S/7NTRR7UdjeAWEUkgM2Pa\n6GFMG330F72P9f3HFOX324270qMjsYiIHBMlCxERiUvJQkRE4lKyEBGRuJQsREQkLiULERGJS8lC\nRETiUrIQEZG4Bs0IbjOrBTYcwyZKgbo+CicRFN+xUXzHRvEdm1SOb5y7l8VrNGiSxbEys6owQ96T\nRfEdG8V3bBTfsUn1+MLQaSgREYlLyUJEROJSsjjkwWQHEIfiOzaK79govmOT6vHFpWsWIiISl44s\nREQkrrRKFmY228xWm1m1md0eY3mumf06WP6qmY3vx9jKzex5M3vTzFaa2a0x2lxoZrvNbGnw+EZ/\nxRcVw3ozWxG8/xF3m7KI7wf7cLmZnd6PsU2N2jdLzazRzD7fpU2/7kMze8TMdpjZG1Hzis1sgZmt\nCZ5HdLPu9UGbNWZ2fT/G9x9m9lbw//dbMyvqZt0ePwsJjO8OM9sc9X/4gW7W7fHvPYHx/ToqtvVm\ntrSbdRO+//qUu6fFA8gE3gEmAjnAMmBalzafAf4rmL4a+HU/xjcKOD2YHgq8HSO+C4HfJ3k/rgdK\ne1j+AeCPgAFnAq8m8f97G5E+5Enbh8D5wOnAG1Hz7gZuD6ZvB74TY71iYG3wPCKYHtFP8V0CZAXT\n34kVX5jPQgLjuwP4Qoj//x7/3hMVX5fl9wDfSNb+68tHOh1ZzASq3X2tu7cAc4E5XdrMAX4aTD8B\nvNfMrD+Cc/et7v56ML0HeBMY0x/v3cfmAD/ziIVAkZmNSkIc7wXecfdjGah5zNz9L0BDl9nRn7Of\nAh+OseqlwAJ3b3D3ncACYHZ/xOfuz7h7W/ByITC2r983rG72Xxhh/t6PWU/xBd8dHwd+1dfvmwzp\nlCzGAJuiXtdw5JfxwTbBH8tuoKRfoosSnP46DXg1xuKzzGyZmf3RzE7q18AiHHjGzBab2U0xlofZ\nz/3harr/I032PjzO3bdC5EcCMDJGm1TZj58icqQYS7zPQiLdEpwme6Sb03ipsP/OA7a7+5pulidz\n//VaOiWLWEcIXbuChWmTUGY2BPgN8Hl3b+yy+HUip1VOBX4APNWfsQXOcffTgfcDnzWz87ssT4V9\nmANcDjweY3Eq7MMwUmE/fhVoAx7tpkm8z0KiPABMAmYAW4mc6ukq6fsPuIaejyqStf+OSjolixqg\nPOr1WGBLd23MLAsYztEdAh8VM8smkigedfcnuy5390Z3bwqm5wPZZlbaX/EF77sleN4B/JbI4X60\nMPs50d4PvO7u27suSIV9CGzvPDUXPO+I0Sap+zG4oP4h4FoPTrB3FeKzkBDuvt3d2929A3iom/dN\n9v7LAj4C/Lq7Nsnaf0crnZLFImCKmU0IfnleDczr0mYe0Nnr5Ergue7+UPpacH7zYeBNd/9uN22O\n77yGYmYzifz/1fdHfMF7FprZ0M5pIhdC3+jSbB7wyaBX1JnA7s5TLv2o2190yd6HgejP2fXA72K0\neRq4xMxGBKdZLgnmJZyZzQa+DFzu7vu6aRPms5Co+KKvgV3RzfuG+XtPpIuBt9y9JtbCZO6/o5bs\nK+z9+SDSU+dtIr0kvhrMu5PIHwVAHpFTF9XAa8DEfoztXCKHycuBpcHjA8DNwM1Bm1uAlUR6diwE\nzu7n/TcxeO9lQRyd+zA6RgPuD/bxCqCyn2MsIPLlPzxqXtL2IZGktRVoJfJr90Yi18GeBdYEz8VB\n20rgJ1Hrfir4LFYDN/RjfNVEzvd3fg47ewiOBub39Fnop/h+Hny2lhNJAKO6xhe8PuLvvT/iC+b/\nT+dnLqptv++/vnxoBLeIiMSVTqehRETkKClZiIhIXEoWIiISl5KFiIjEpWQhIiJxKVmIxGFm7V2q\n2fZZBVMzGx9dsVQkVWUlOwCRAWC/u89IdhAiyaQjC5GjFNyP4Dtm9lrwmBzMH2dmzwaF7p41s4pg\n/nHB/SGWBY+zg01lmtlDFrmPyTNmlh+0/5yZrQq2MzdJ/0wRQMlCJIz8Lqehropa1ujuM4EfAvcF\n835IpEz7KUSK8H0/mP994EWPFDE8ncjIXYApwP3ufhKwC/hoMP924LRgOzcn6h8nEoZGcIvEYWZN\n7j4kxvz1wHvcfW1QBHKbu5eYWR2REhStwfyt7l5qZrXAWHdvjtrGeCL3rZgSvP4ykO3u/2ZmfwKa\niFTGfcqDAogiyaAjC5Fj491Md9cmluao6XYOXUv8IJE6W2cAi4NKpiJJoWQhcmyuinr+WzD9CpEq\npwDXAi8H088CnwYws0wzG9bdRs0sAyh39+eBLwFFwBFHNyL9Rb9UROLLN7OlUa//5O6d3WdzzexV\nIj+8rgnmfQ54xMy+CNQCNwTzbwUeNLMbiRxBfJpIxdJYMoFfmNlwIpV873X3XX32LxLpJV2zEDlK\nwTWLSnevS3YsIomm01AiIhKXjixERCQuHVmIiEhcShYiIhKXkoWIiMSlZCEiInEpWYiISFxKFiIi\nEtf/B+sPcd71hg36AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efda08a19b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(train_loss_avg)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross-entropy loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively: Load Pre-Trained Model\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp.load_state_dict(torch.load('./pretrained/multilayer_perceptron.pth'))\n",
    "\n",
    "# this is how the model parameters can be saved:\n",
    "# torch.save(mlp.state_dict(), './pretrained/my_multilayer_perceptron.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on the Test Set\n",
    "-------------------------\n",
    "\n",
    "The best current methods achieve a classification error percentage of around 0.21%. See [here](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354) for a leaderboard. Also notice that there is some overfitting: the average loss is significantly higher than for the training set. Overfitting can be reduced by adding dropout between the fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss: 0.075974\n",
      "classification error: 1.820000%\n"
     ]
    }
   ],
   "source": [
    "# set to evaluation mode\n",
    "mlp.eval()\n",
    "\n",
    "num_incorrect = 0\n",
    "test_loss_avg = 0\n",
    "num_batches = 0\n",
    "num_instances = 0\n",
    "for image_batch, label_batch in test_dataloader:\n",
    "    \n",
    "    image_batch = Variable(image_batch)\n",
    "    label_batch = Variable(label_batch)\n",
    "    if use_gpu:\n",
    "        image_batch = image_batch.cuda()\n",
    "        label_batch = label_batch.cuda()\n",
    "    \n",
    "    # class predictions\n",
    "    prediction_batch = mlp(image_batch)\n",
    "    \n",
    "    # get number of correct and incorrect class predictions\n",
    "    _, predicted_label = prediction_batch.max(dim=1)\n",
    "    num_incorrect += (predicted_label != label_batch).sum().data[0]\n",
    "\n",
    "    # cross-entropy loss\n",
    "    loss = F.nll_loss(prediction_batch, label_batch)\n",
    "\n",
    "    test_loss_avg += loss.data[0]\n",
    "    num_batches += 1\n",
    "    num_instances += image_batch.size(0)\n",
    "    \n",
    "test_loss_avg /= num_batches\n",
    "print('average loss: %f' % (test_loss_avg))\n",
    "print('classification error: %f%%' % ((num_incorrect / num_instances)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
