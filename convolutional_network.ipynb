{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Networks (ConvNets)\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter Settings\n",
    "-------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "use_dropout = False\n",
    "use_gpu = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST Data Loading\n",
    "-------------------\n",
    "\n",
    "MNIST images show digits from 0-9 in 28x28 grayscale images. We normalize and center them around 0, which gives a slight performance boost during training.\n",
    "We create both a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = MNIST(root='./data/MNIST', download=True, train=True, transform=img_transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = MNIST(root='./data/MNIST', download=True, train=False, transform=img_transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConvNet Definition\n",
    "-----------------------\n",
    "Compare the number of parameters to the multi-layer perceptron: the convnet has less than 5% of the MLPs parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 25384\n"
     ]
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=4, stride=2, padding=1) # out: 8 x 14 x 14\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=4, stride=2, padding=1) # out: 16 x 7 x 7\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=4, stride=2, padding=1) # out: 32 x 3 x 3\n",
    "        if use_dropout:\n",
    "            self.do1 = nn.Dropout2d(p=0.5)\n",
    "        self.fc1 = nn.Linear(288, 50)\n",
    "        if use_dropout:\n",
    "            self.do2 = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(50, 10) # 10 outputs: probability for each digit class\n",
    "\n",
    "    def forward(self, x):\n",
    "        # convolutional part\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        if use_dropout:\n",
    "            x = self.do1(x)\n",
    "        x = x.view(x.size(0), -1) # flatten batch of multi-channel feature maps to a batch of feature vectors\n",
    "        \n",
    "        # fully connected part\n",
    "        x = F.relu(self.fc1(x))\n",
    "        if use_dropout:\n",
    "            x = self.do2(x)\n",
    "        x = F.log_softmax(self.fc2(x), dim=1) # last activation is log softmax to get log class probabilities\n",
    "        \n",
    "        return x\n",
    "\n",
    "convnet = ConvNet()\n",
    "if use_gpu:\n",
    "    convnet = convnet.cuda()\n",
    "\n",
    "num_params = sum(p.numel() for p in convnet.parameters() if p.requires_grad)\n",
    "print('Number of parameters: %d' % num_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train ConvNet\n",
    "--------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Epoch [1 / 20] average reconstruction error: 0.438431\n",
      "Epoch [2 / 20] average reconstruction error: 0.124590\n",
      "Epoch [3 / 20] average reconstruction error: 0.088712\n",
      "Epoch [4 / 20] average reconstruction error: 0.072866\n",
      "Epoch [5 / 20] average reconstruction error: 0.059593\n",
      "Epoch [6 / 20] average reconstruction error: 0.052359\n",
      "Epoch [7 / 20] average reconstruction error: 0.044972\n",
      "Epoch [8 / 20] average reconstruction error: 0.040244\n",
      "Epoch [9 / 20] average reconstruction error: 0.036166\n",
      "Epoch [10 / 20] average reconstruction error: 0.032120\n",
      "Epoch [11 / 20] average reconstruction error: 0.029204\n",
      "Epoch [12 / 20] average reconstruction error: 0.025697\n",
      "Epoch [13 / 20] average reconstruction error: 0.024381\n",
      "Epoch [14 / 20] average reconstruction error: 0.020237\n",
      "Epoch [15 / 20] average reconstruction error: 0.020390\n",
      "Epoch [16 / 20] average reconstruction error: 0.017248\n",
      "Epoch [17 / 20] average reconstruction error: 0.015105\n",
      "Epoch [18 / 20] average reconstruction error: 0.015938\n",
      "Epoch [19 / 20] average reconstruction error: 0.012565\n",
      "Epoch [20 / 20] average reconstruction error: 0.013763\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(params=convnet.parameters(), lr=learning_rate)\n",
    "\n",
    "# set to training mode\n",
    "convnet.train()\n",
    "\n",
    "train_loss_avg = []\n",
    "\n",
    "print('Training ...')\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss_avg.append(0)\n",
    "    num_batches = 0\n",
    "    \n",
    "    for image_batch, label_batch in train_dataloader:\n",
    "        \n",
    "        image_batch = Variable(image_batch)\n",
    "        label_batch = Variable(label_batch)\n",
    "        if use_gpu:\n",
    "            image_batch = image_batch.cuda()\n",
    "            label_batch = label_batch.cuda()\n",
    "        \n",
    "        # class predictions\n",
    "        prediction_batch = convnet(image_batch)\n",
    "        \n",
    "        # The cross-entropy loss.\n",
    "        # The first input are the predicted log class probabilities.\n",
    "        # The ground truth probabilites for each image are expected to be\n",
    "        # 1 for a single class and 0 for all other classes.\n",
    "        # This function expects as second input the index of the class with probability 1.\n",
    "        # (this function is not called cross-entropy, since this function assumes\n",
    "        # that the inputs are log probabilities, not probabilities).\n",
    "        loss = F.nll_loss(prediction_batch, label_batch)\n",
    "        \n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # one step of the optmizer (using the gradients from backpropagation)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss_avg[-1] += loss.data[0]\n",
    "        num_batches += 1\n",
    "        \n",
    "    train_loss_avg[-1] /= num_batches\n",
    "    print('Epoch [%d / %d] average loss: %f' % (epoch+1, num_epochs, train_loss_avg[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Training Curve\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUBARkQKFgoiIFCgURESk4P8DxAQhACrhinkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f694d7fbcf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(train_loss_avg)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross-entropy loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively: Load Pre-Trained Model\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convnet.load_state_dict(torch.load('./pretrained/convolutional_network.pth'))\n",
    "# convnet.load_state_dict(torch.load('./pretrained/convolutional_network_dropout.pth'))\n",
    "\n",
    "# this is how the model parameters can be saved:\n",
    "# torch.save(convnet.state_dict(), './pretrained/my_convolutional_network.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on the Test Set\n",
    "-------------------------\n",
    "\n",
    "The best current methods achieve a classification error percentage of around 0.21%. See [here](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354) for a leaderboard.\n",
    "\n",
    "Compared to the multi-layer perceptron, the convnet achieves less error using roughly 4% as many parameters.\n",
    "\n",
    "Also notice that there is some overfitting: the average loss is significantly higher than for the training set.\n",
    "Overfitting can be reduced by adding dropout between the fully connected layers. Retrain with `use_dropout` set to `True` or load the pre-trained `convolutional_network_dropout.pth` to see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss: 0.054664\n",
      "classification error: 1.480000%\n"
     ]
    }
   ],
   "source": [
    "# set to evaluation mode\n",
    "convnet.eval()\n",
    "\n",
    "num_incorrect = 0\n",
    "test_loss_avg = 0\n",
    "num_batches = 0\n",
    "num_instances = 0\n",
    "for image_batch, label_batch in test_dataloader:\n",
    "    \n",
    "    image_batch = Variable(image_batch)\n",
    "    label_batch = Variable(label_batch)\n",
    "    if use_gpu:\n",
    "        image_batch = image_batch.cuda()\n",
    "        label_batch = label_batch.cuda()\n",
    "    \n",
    "    # class predictions\n",
    "    prediction_batch = convnet(image_batch)\n",
    "    \n",
    "    # get number of correct and incorrect class predictions\n",
    "    _, predicted_label = prediction_batch.max(dim=1)\n",
    "    num_incorrect += (predicted_label != label_batch).sum().data[0]\n",
    "\n",
    "    # cross-entropy loss\n",
    "    loss = F.nll_loss(prediction_batch, label_batch)\n",
    "\n",
    "    test_loss_avg += loss.data[0]\n",
    "    num_batches += 1\n",
    "    num_instances += image_batch.size(0)\n",
    "    \n",
    "test_loss_avg /= num_batches\n",
    "print('average loss: %f' % (test_loss_avg))\n",
    "print('classification error: %f%%' % ((num_incorrect / num_instances)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
