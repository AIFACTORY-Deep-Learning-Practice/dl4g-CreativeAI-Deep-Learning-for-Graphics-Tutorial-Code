{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight Initialization\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter Settings\n",
    "-------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "use_gpu = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST Data Loading\n",
    "-------------------\n",
    "\n",
    "MNIST images show digits from 0-9 in 28x28 grayscale images. We normalize and center them around 0, which gives a slight performance boost during training.\n",
    "We create both a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = MNIST(root='./data/MNIST', download=True, train=True, transform=img_transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = MNIST(root='./data/MNIST', download=True, train=False, transform=img_transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConvNet Definition\n",
    "-----------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters for each network: 25384\n"
     ]
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, init_type):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=4, stride=2, padding=1) # out: 8 x 14 x 14\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=4, stride=2, padding=1) # out: 16 x 7 x 7\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=4, stride=2, padding=1) # out: 32 x 3 x 3\n",
    "        self.fc1 = nn.Linear(288, 50)\n",
    "        self.fc2 = nn.Linear(50, 10) # 10 outputs: probability for each digit class\n",
    "        \n",
    "        self.init_weights(init_type)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # convolutional part\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1) # flatten batch of multi-channel feature maps to a batch of feature vectors\n",
    "        \n",
    "        # fully connected part\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.log_softmax(self.fc2(x), dim=1) # last activation is log softmax to get log class probabilities\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def init_weights(self, init_type):\n",
    "        # iterate over all parameter tensors\n",
    "        for m in self.modules():\n",
    "\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                if init_type == 'zero':\n",
    "\n",
    "                    # initialize to zero\n",
    "                    m.weight.data.zero_()\n",
    "\n",
    "                elif init_type == 'normal':\n",
    "\n",
    "                    # initialization with a normal distribution of small variance\n",
    "                    m.weight.data.normal_(0, 0.01)\n",
    "\n",
    "                elif init_type == 'kaiming':\n",
    "\n",
    "                    # kaiming initialization for convolutional layers\n",
    "                    # this is equivalent to nn.init.kaiming_normal(m.weight.data)\n",
    "                    fan_in = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                    m.weight.data.normal_(0, math.sqrt(2. / fan_in))\n",
    "\n",
    "                else:\n",
    "                    raise ValueError('bad initialization type')\n",
    "\n",
    "                # bias can be initialized to 0\n",
    "                m.bias.data.zero_()\n",
    "            \n",
    "            elif isinstance(m, nn.Linear):\n",
    "                if init_type == 'zero':\n",
    "\n",
    "                    # initialize to zero\n",
    "                    m.weight.data.zero_()\n",
    "\n",
    "                elif init_type == 'normal':\n",
    "\n",
    "                    # initialization with a normal distribution of small variance\n",
    "                    m.weight.data.normal_(0, 0.01)\n",
    "\n",
    "                elif init_type == 'kaiming':\n",
    "\n",
    "                    # kaiming initialization for convolutional layers\n",
    "                    # this is equivalent to nn.init.kaiming_normal(m.weight.data)\n",
    "                    fan_in = m.in_features\n",
    "                    m.weight.data.normal_(0, math.sqrt(2. / fan_in))\n",
    "\n",
    "                else:\n",
    "                    raise ValueError('bad initialization type')\n",
    "                \n",
    "                # bias can be initialized to 0\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "convnet_zero = ConvNet('zero')\n",
    "convnet_normal = ConvNet('normal')\n",
    "convnet_kaiming = ConvNet('kaiming')\n",
    "if use_gpu:\n",
    "    convnet_zero = convnet_zero.cuda()\n",
    "    convnet_normal = convnet_normal.cuda()\n",
    "    convnet_kaiming = convnet_kaiming.cuda()\n",
    "\n",
    "num_params = sum(p.numel() for p in convnet_zero.parameters() if p.requires_grad)\n",
    "print('Number of parameters for each network: %d' % num_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train ConvNets\n",
    "--------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training convnet with zero initialization ...\n",
      "Epoch [1 / 20] average reconstruction error: 2.301648\n",
      "Epoch [2 / 20] average reconstruction error: 2.301277\n",
      "Epoch [3 / 20] average reconstruction error: 2.301270\n",
      "Epoch [4 / 20] average reconstruction error: 2.301271\n",
      "Epoch [5 / 20] average reconstruction error: 2.301265\n",
      "Epoch [6 / 20] average reconstruction error: 2.301262\n",
      "Epoch [7 / 20] average reconstruction error: 2.301260\n",
      "Epoch [8 / 20] average reconstruction error: 2.301275\n",
      "Epoch [9 / 20] average reconstruction error: 2.301264\n",
      "Epoch [10 / 20] average reconstruction error: 2.301272\n",
      "Epoch [11 / 20] average reconstruction error: 2.301224\n",
      "Epoch [12 / 20] average reconstruction error: 2.301279\n",
      "Epoch [13 / 20] average reconstruction error: 2.301273\n",
      "Epoch [14 / 20] average reconstruction error: 2.301262\n",
      "Epoch [15 / 20] average reconstruction error: 2.301255\n",
      "Epoch [16 / 20] average reconstruction error: 2.301270\n",
      "Epoch [17 / 20] average reconstruction error: 2.301252\n",
      "Epoch [18 / 20] average reconstruction error: 2.301291\n",
      "Epoch [19 / 20] average reconstruction error: 2.301273\n",
      "Epoch [20 / 20] average reconstruction error: 2.301261\n",
      "Training convnet with normal initialization ...\n",
      "Epoch [1 / 20] average reconstruction error: 0.825222\n",
      "Epoch [2 / 20] average reconstruction error: 0.217983\n",
      "Epoch [3 / 20] average reconstruction error: 0.131639\n",
      "Epoch [4 / 20] average reconstruction error: 0.099107\n",
      "Epoch [5 / 20] average reconstruction error: 0.082674\n",
      "Epoch [6 / 20] average reconstruction error: 0.071990\n",
      "Epoch [7 / 20] average reconstruction error: 0.063925\n",
      "Epoch [8 / 20] average reconstruction error: 0.058220\n",
      "Epoch [9 / 20] average reconstruction error: 0.053008\n",
      "Epoch [10 / 20] average reconstruction error: 0.049556\n",
      "Epoch [11 / 20] average reconstruction error: 0.043981\n",
      "Epoch [12 / 20] average reconstruction error: 0.040196\n",
      "Epoch [13 / 20] average reconstruction error: 0.038482\n",
      "Epoch [14 / 20] average reconstruction error: 0.034878\n",
      "Epoch [15 / 20] average reconstruction error: 0.032269\n",
      "Epoch [16 / 20] average reconstruction error: 0.029315\n",
      "Epoch [17 / 20] average reconstruction error: 0.028119\n",
      "Epoch [18 / 20] average reconstruction error: 0.025148\n",
      "Epoch [19 / 20] average reconstruction error: 0.023774\n",
      "Epoch [20 / 20] average reconstruction error: 0.022287\n",
      "Training convnet with kaiming initialization ...\n",
      "Epoch [1 / 20] average reconstruction error: 0.377827\n",
      "Epoch [2 / 20] average reconstruction error: 0.107877\n",
      "Epoch [3 / 20] average reconstruction error: 0.071730\n",
      "Epoch [4 / 20] average reconstruction error: 0.057426\n",
      "Epoch [5 / 20] average reconstruction error: 0.047791\n",
      "Epoch [6 / 20] average reconstruction error: 0.038826\n",
      "Epoch [7 / 20] average reconstruction error: 0.033689\n",
      "Epoch [8 / 20] average reconstruction error: 0.029972\n",
      "Epoch [9 / 20] average reconstruction error: 0.025827\n",
      "Epoch [10 / 20] average reconstruction error: 0.022862\n",
      "Epoch [11 / 20] average reconstruction error: 0.020311\n",
      "Epoch [12 / 20] average reconstruction error: 0.018939\n",
      "Epoch [13 / 20] average reconstruction error: 0.015396\n",
      "Epoch [14 / 20] average reconstruction error: 0.013862\n",
      "Epoch [15 / 20] average reconstruction error: 0.014338\n",
      "Epoch [16 / 20] average reconstruction error: 0.012522\n",
      "Epoch [17 / 20] average reconstruction error: 0.011540\n",
      "Epoch [18 / 20] average reconstruction error: 0.009553\n",
      "Epoch [19 / 20] average reconstruction error: 0.008813\n",
      "Epoch [20 / 20] average reconstruction error: 0.011132\n"
     ]
    }
   ],
   "source": [
    "def train_convnet(convnet):\n",
    "    optimizer = torch.optim.Adam(params=convnet.parameters(), lr=learning_rate)\n",
    "\n",
    "    # set to training mode\n",
    "    convnet.train()\n",
    "\n",
    "    train_loss_avg = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss_avg.append(0)\n",
    "        num_batches = 0\n",
    "\n",
    "        for image_batch, label_batch in train_dataloader:\n",
    "\n",
    "            image_batch = Variable(image_batch)\n",
    "            label_batch = Variable(label_batch)\n",
    "            if use_gpu:\n",
    "                image_batch = image_batch.cuda()\n",
    "                label_batch = label_batch.cuda()\n",
    "\n",
    "            # class predictions\n",
    "            prediction_batch = convnet(image_batch)\n",
    "\n",
    "            # The cross-entropy loss.\n",
    "            # The first input are the predicted log class probabilities.\n",
    "            # The ground truth probabilites for each image are expected to be\n",
    "            # 1 for a single class and 0 for all other classes.\n",
    "            # This function expects as second input the index of the class with probability 1.\n",
    "            # (this function is not called cross-entropy, since this function assumes\n",
    "            # that the inputs are log probabilities, not probabilities).\n",
    "            loss = F.nll_loss(prediction_batch, label_batch)\n",
    "\n",
    "            # backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # one step of the optmizer (using the gradients from backpropagation)\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss_avg[-1] += loss.data[0]\n",
    "            num_batches += 1\n",
    "\n",
    "        train_loss_avg[-1] /= num_batches\n",
    "        print('Epoch [%d / %d] average loss: %f' % (epoch+1, num_epochs, train_loss_avg[-1]))\n",
    "    \n",
    "    return train_loss_avg\n",
    "        \n",
    "print('Training convnet with zero initialization ...')\n",
    "train_loss_zero = train_convnet(convnet_zero)\n",
    "print('Training convnet with normal initialization ...')\n",
    "train_loss_normal = train_convnet(convnet_normal)\n",
    "print('Training convnet with kaiming initialization ...')\n",
    "train_loss_kaiming = train_convnet(convnet_kaiming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively: Load Pre-Trained Model and Loss Histories\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convnet_zero.load_state_dict(torch.load('./pretrained/convnet_init_zero.pth'))\n",
    "convnet_normal.load_state_dict(torch.load('./pretrained/convnet_init_normal.pth'))\n",
    "convnet_kaiming.load_state_dict(torch.load('./pretrained/convnet_init_kaiming.pth'))\n",
    "train_loss_zero = torch.load('./pretrained/convnet_init_zero_losshist.pth')\n",
    "train_loss_normal = torch.load('./pretrained/convnet_init_normal_losshist.pth')\n",
    "train_loss_kaiming = torch.load('./pretrained/convnet_init_kaiming_losshist.pth')\n",
    "\n",
    "# this is how the model parameters and loss histories can be saved:\n",
    "# torch.save(convnet_zero.state_dict(), './pretrained/my_convnet_init_zero.pth')\n",
    "# torch.save(convnet_normal.state_dict(), './pretrained/my_convnet_init_normal.pth')\n",
    "# torch.save(convnet_kaiming.state_dict(), './pretrained/my_convnet_init_kaiming.pth')\n",
    "# torch.save(train_loss_zero, './pretrained/my_convnet_init_zero_losshist.pth')\n",
    "# torch.save(train_loss_normal, './pretrained/my_convnet_init_normal_losshist.pth')\n",
    "# torch.save(train_loss_kaiming, './pretrained/my_convnet_init_kaiming_losshist.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Training Curve\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fad0065ca90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(train_loss_zero, label='zero')\n",
    "plt.plot(train_loss_normal, label='normal')\n",
    "plt.plot(train_loss_kaiming, label='kaiming')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross-entropy loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
